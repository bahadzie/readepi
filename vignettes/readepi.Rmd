---
title: "readepi-vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{readepi-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(readepi)
```

# Reading data from file or directory

`readepi` provides functions for reading data from `common health information systems` as well as from various file types. When several files of different formats are stored in the same folder, the user can provide `readepi` with a specific pattern, allowing reading only the matching files.     

When reading data from file or directory, the function expects the following arguments:   
* *file.path*: the path to the file of interest. When several files need to be imported from a directory, this should be the path to that directory,      
* *sep*: the separator between the columns in the file. This is only required for space-separated files,     
* *format*: a string used to specify the file format. This is useful when a file does not have an extension, or has a file extension that does not match its actual type,      
* *which*: a string used to specify which objects should be extracted (e.g. the name of the excel sheet to import),     
* *pattern*: when provided, only files that contain this pattern will be imported from the specified directory.    
The function will return a list of data frames (if several files were imported from a directory).    

## importing data from JSON file
Many database management systems (DBMS) can export data into `JSON` format that can be read into R using the `readepi()` function.      
```{r eval=FALSE}
file <- system.file("extdata", "test.json", package = "readepi")
data <- readepi(file.path = file)
```

## importing data from excel file 
`readepi()` can import data from MS excel file with a single sheet. The user must specify the names of the excel sheets with the data of interest when the files contains several sheets.      
```{r eval=FALSE}
# IMPORTING DATA FROM THE SECOND EXCEL SHEET
file <- system.file("extdata", "test.xlsx", package = "readepi")
data <- readepi(file.path = file, which = "Sheet2")

# IMPORTING DATA FROM THE FIRST AND SECOND EXCEL SHEETS
file <- system.file("extdata", "test.xlsx", package = "readepi")
data <- readepi(file.path = file, which = c("Sheet2", "Sheet1"))
```

## importing data from several files in a directory
`readepi()` can be used to read data from multiple files that are all stored in the same directory. When there are different file format in that directory, the user is expected to specify the file type of interest with the `pattern` argument.     
```{r eval=FALSE}
# READING ALL FILES IN THE GIVEN DIRECTOR
dir.path <- system.file("extdata", package = "readepi")
data <- readepi(file.path = dir.path)

# READING ONLY '.txt' FILES
data <- readepi(file.path = dir.path, pattern = ".txt")

# READING '.txt' and '.xlsx' FILES
data <- readepi(file.path = dir.path, pattern = c(".txt", ".xlsx"))
```

# importing from DBMS (database management systems)
Users should be granted with read access to be able to pull data from the RDBMS. 

## Reading data from relational database management systems (RDBMS): HDSS, EMRS, REDCap
Research data are usually stored in either relational databases or NoSQL databases. For instance, at the MRCG, project data are stored in relational databases. The HDSS and EMRS host databases that run under MS SQL Server, while REDCap (that uses an EAV schema) run under a MySQL server.    
To import data from a HDSS or EMRS (MS SQL Server) into R, some dependencies need to be installed first.    

### installation of dependencies
If you are using a Unix-based system, you will need to install the MS ODBC driver that is compatible with the version of the target MS SQL server. For **SQL server 2019, version 15.0**, we installed **ODBC Driver 17 for SQL Server** on the mac OS which is compatible with the test server.    

#### installation of MS SQL driver on Mac
Mac users can follow the instructions below to install the MS SQL ODBC driver.     

##### installation of MS SQL driver 17 or 18 on Mac
```{bash eval=FALSE}
driver=17
brew install unixodbc
brew tap microsoft/mssql-release https://github.com/Microsoft/homebrew-mssql-release
brew update
brew install msodbcsql${driver}
brew install mssql-tools
ODBCSYSINI=/
```

##### installation of MS SQL driver 13.1 on Mac
```{bash eval=FALSE}
brew install unixodbc
brew tap microsoft/mssql-release https://github.com/Microsoft/homebrew-mssql-release
brew update
brew install msodbcsql@13.1.9.2
brew install mssql-tools@14.0.6.0
ODBCSYSINI=/
```

#### installation of MS SQL driver version 17 or 18 on `Ubuntu`
Note that this requires **Ubuntu 16.04 and above**. Open the terminal and type the code below:         
```{bash eval=FALSE}
driver=17
sudo su
curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -
curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list > /etc/apt/sources.list.d/mssql-release.list
exit

sudo apt-get update
sudo ACCEPT_EULA=Y apt-get install -y msodbcsql${driver}
sudo ACCEPT_EULA=Y apt-get install -y mssql-tools
echo 'export PATH="$PATH:/opt/mssql-tools/bin"' >> ~/.bashrc
source ~/.bashrc
sudo apt-get install -y unixodbc-dev
```

#### installation of MS SQL driver version 13.1 on `Ubuntu`
Note that this works for older versions of Ubuntu, including version 16.04.   
```{bash eval=FALSE}
sudo su
curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -
curl https://packages.microsoft.com/config/ubuntu/16.04/prod.list > /etc/apt/sources.list.d/mssql-release.list
exit
sudo apt-get update
sudo ACCEPT_EULA=Y apt-get install msodbcsql
sudo ACCEPT_EULA=Y apt-get install mssql-tools
echo 'export PATH="$PATH:/opt/mssql-tools/bin"' >> ~/.bashrc
source ~/.bashrc
sudo apt-get install unixodbc-dev
```

#### installation of MS SQL driver on other Linux distributions
When working on a Linux distribution other than Ubuntu, follow the instructions [here](https://learn.microsoft.com/en-us/sql/connect/odbc/linux-mac/installing-the-microsoft-odbc-driver-for-sql-server?view=sql-server-ver15&tabs=ubuntu18-install%2Cubuntu17-install%2Cubuntu16-install%2Cubuntu16-13-install%2Crhel7-offline) for the MS SQL driver installation process.           


After the driver installation, the list of drivers can be displayed in R using:       
```{r eval=FALSE}
odbc::odbcListDrivers()
```

If the command above does not return the list of installed drivers or if you are facing issues during the driver installation process, consult    
[the odbc github page](https://github.com/r-dbi/odbc#installation) or the [MS documentation on this topic](https://learn.microsoft.com/en-us/sql/connect/odbc/linux-mac/install-microsoft-odbc-driver-sql-server-macos?view=sql-server-ver15)     


**Note that it is important to view the data that is stored in the MS SQL server. We recommend to install a GUI such as `Azure Data Studio` for that purpose.**         

## importing from MS SQL server
To be able to read data from a MS SQL server, the **read_epi()** expects the following arguments:     
* *credentials.file*: the path to the file with the user-specific credential details for the projects of interest. This is a tab-delimited file with the following 7  columns:     

`user_name`: the user name,    
`password`: the user password (for REDCap, this corresponds to the **token** that serves as password to the project),    
`host_name`: the host name (for HDSS and EMRS) or the URI (for REDCap),    
`project_id`: the project ID (for REDCap) or the name of the database (for HDSS and EMRS) you are access to,   
`comment`: a summary description about the project or database of interest,     
`dbms`: the name of the DBMS: 'redcap' or 'REDCap' when reading from REDCap, 'sqlserver' or 'SQLServer' when reading from MS SQL Server,    
`port`: the port ID (used for MS SQL Servers only).    

* *project.id*: for relational DB, this is the name of the database that contains the table from which the data should be pulled. Otherwise, it is the project ID you were given access to. Note that this should be similar to the value of the **project_id** field in the credential file.  
* *driver.name*: the name of the MS driver (only for HDSS and EMRS). use  `odbc::odbcListDrivers()` to display the list of installed drivers,    
* *table.name*: the name of the target table (only for HDSS and EMRS),   
* *records*: a vector or a comma-separated string of a subset of subject IDs. When specified, only the records that correspond to these subjects will be imported,    
* *fields*: a vector or a comma-separated string of column names. If provided, only those columns will be imported,     
* *id.position*: the column position of the variable that unique identifies the subjects. default is 1.    
* *id.col.name*: the name of the column that unique identifies the subjects.


Use the `show_example_file()` as below to view the credentials file used as template in the **readepi** package.      
```{r eval=FALSE}
# DISPLAY THE STRUCTURE OF THE CREDENTIALS FILE
show_example_file()
```
All demos in the sections below rely on the credentials stored in the template file, that is declared as following:
```{r eval=FALSE}
# DEFINING THE CREDENTIALS FILE
# credentials.file <- system.file("extdata", "test.ini", package = "readepi")
credentials.file <- system.file("extdata", "test.ini", package = "readepi")
```

### list the names of all tables in the database
To displays the list of tables from the database of interest, use:  
```{r eval=FALSE}
show_tables(
  credentials.file = credentials.file,
  project.id = "TEST_READEPI", # this is the database name
  driver.name = "ODBC Driver 17 for SQL Server"
)
```

Note that in the above, the value for the `project.id` argument is the name of the database of interest.    

### importing the data    
```{r eval=FALSE}
# READING ALL FIELDS AND ALL RECORDS FROM ONE TABLE (`DSS_EVENTS`)
data <- readepi(credentials.file,
  project.id = "TEST_READEPI",
  driver.name = "ODBC Driver 17 for SQL Server",
  table.name = "covid"
)

# READING SPECIFIED FIELDS AND ALL RECORDS FROM ONE TABLE
fields <- "date,sex,age" # same as fields = "idate, sex, age" and fields = c("date","sex","age")
data <- readepi(credentials.file,
  project.id = "TEST_READEPI",
  driver.name = "ODBC Driver 17 for SQL Server",
  table.name = "covid",
  fields = fields
)

# READING SPECIFIED RECORDS AND ALL FIELDS FROM ONE TABLE
records <- "e38000191,e38000247,e38000020,e38000130,e38000122,e38000223" # same as records=c("e38000191","e38000247","e38000020","e38000130","e38000122","e38000223") and records = "e38000191, e38000247, e38000020, e38000130, e38000122, e38000223"
data <- readepi(credentials.file,
  project.id = "TEST_READEPI",
  driver.name = "ODBC Driver 17 for SQL Server",
  table.name = "covid",
  records = records,
  id.position = 5
)

# READING SPECIFIED FIELDS AND RECORDS ONE THE TABLE
fields <- "date,sex,age,ccg_code"
data <- readepi(credentials.file,
  project.id = "TEST_READEPI",
  driver.name = "ODBC Driver 17 for SQL Server",
  table.name = "covid",
  records = records,
  fields = fields,
  id.col.name = "ccg_code"
)

# READING DATA FROM SEVERAL TABLES
table.names <- "covid,ebola,iris"
data <- readepi(credentials.file,
  project.id = "TEST_READEPI",
  driver.name = "ODBC Driver 17 for SQL Server",
  table.name = table.names
)

# READING DATA FROM SEVERAL TABLES AND SUBSETTING FIELDS ACROSS TABLES
table.names <- "covid, ebola, iris"
fields <- c(
  "date,sex,age,ccg_code", "id,date_of_onset,district",
  "Sepal.Length,Species"
) # the first string in the field vector corresponds to the name of the columns of interest from the first table specified in the `table.names` argument and so on...
data <- readepi(credentials.file,
  project.id = "TEST_READEPI",
  driver.name = "ODBC Driver 17 for SQL Server",
  table.name = table.names,
  fields = fields
)

# READING DATA FROM SEVERAL TABLES AND SUBSETTING RECORDS ACROSS TABLES
records <- c(
  "e38000191,e38000247,e38000020,e38000130,e38000122,e38000223",
  "9375,881,4539",
  "setosa"
) # "note that first string in the records vector corresponds to the records of interest from the first table specified in the `table.name` argument and so on... when the id column is not the first column in a table, use the `id.position`"
data <- readepi(credentials.file,
  project.id = "TEST_READEPI",
  driver.name = "ODBC Driver 17 for SQL Server",
  table.name = table.names,
  records = records,
  id.position = c(5, 1, 5)
)

# READING DATA FROM SEVERAL TABLES AND SUBSETTING RECORDS AND FIELDS ACROSS TABLES
fields <- c(
  "date,sex,age,ccg_code", "id,date_of_onset,district",
  "Sepal.Length,Species"
)
records <- c(
  "e38000191,e38000247,e38000020,e38000130,e38000122,e38000223",
  "9375,881,4539",
  "setosa"
)
data <- readepi(credentials.file,
  project.id = "TEST_READEPI",
  driver.name = "ODBC Driver 17 for SQL Server",
  table.name = table.names,
  records = records,
  fields = fields,
  id.col.name = c("ccg_code", "id", "Species")
)
```

## importing from REDCap
To import data from REDCap, the user must call the `readepi` function with the following arguments:     

* *credentials.file*: the credentials file (required)
* *project.id*: the project ID (required)
* *records*: the list of the desired records (optional)
* *fields*: the list of the desired columns (optional)

Both the data and its associated metadata will be will be returned after a successful import.    

```{r eval=FALSE}
# READING ALL FIELDS AND RECORDS FROM A REDCap PROJECT
data <- readepi(
  credentials.file = credentials.file,
  project.id = "Pats__Covid_19_Cohort_1_Screening"
)
project.data <- data$data
project.metadeta <- data$metadata

# READING SPECIFIC FIELDS AND ALL RECORDS FROM THE PROJECT
fields <- c("day_1_q_ran_id", "redcap_event_name", "day_1_q_1a", "day_1_q_1b", "day_1_q_1c", "day_1_q_1", "day_1_q_2", "day_1_q_3", "day_1_q_4", "day_1_q_5")
data <- readepi(credentials.file,
  project.id = "Pats__Covid_19_Cohort_1_Screening",
  fields = fields
)

# READING SPECIFIC RECORDS AND ALL FIELDS FROM THE PROJECT
records <- c("C10001/3", "C10002/1", "C10003/7", "C10004/5", "C10005/9", "C10006/8", "C10007/6", "C10008/4", "C10009/2", "C10010/1")
data <- readepi(credentials.file,
  project.id = "Pats__Covid_19_Cohort_1_Screening",
  records = records,
  id.col.name = "day_1_q_ran_id"
)

# READING SPECIFIC RECORDS AND FIELDS FROM THE PROJECT
data <- readepi(credentials.file,
  project.id = "Pats__Covid_19_Cohort_1_Screening",
  records = records,
  fields = fields
)
project.data <- data$data
project.metadeta <- data$metadata
```


## importing from DHIS2
To import data from **DHIS2**, the user must call the `readepi` function with the following arguments:     

* *credentials.file*: the credentials file (required)
* *project.id*: the project ID (required)
* *dataset*: the dataset identifier (required)
* *organisation.unit*: the organisation unit identifier (required)    
* *data.element.group*: the data element group (optional)    
* *start.date*: the start date for the time span of the values to export (required)    
* *end.date*: the end date for the time span of the values to export (required)   
* *id.col.name*: the column name with the records of interest (optional)    
* *records*: the list of the desired records (optional)     
* *fields*: the list of the desired columns (optional)    

```{r eval=FALSE}
# GETTING THE DATA ELEMENT IDENTIFIERS AND NAMES
data.elements <- get_data_elements(
  base.url = "https://play.dhis2.org/dev/",
  username = "admin",
  password = "district"
)

# GETTING THE DATASET IDENTIFIERS AND NAMES
datasets <- get_data_sets(
  base.url = "https://play.dhis2.org/dev/",
  username = "admin",
  password = "district"
)

# GETTING THE ORGANISATION UNIT IDENTIFIERS AND NAMES
organisation.units <- get_data_sets(
  base.url = "https://play.dhis2.org/dev/",
  username = "admin",
  password = "district"
)

# GETTING THE DATA ELEMENT GROUP IDENTIFIERS AND NAMES
data.element.groups <- get_organisation_units(
  base.url = "https://play.dhis2.org/dev/",
  username = "admin",
  password = "district"
)

# READING THE DATASET ID `pBOMPrpg1QX`
data <- readepi(
  credentials.file = credentials.file,
  project.id = "DHIS2_DEMO",
  dataset = "pBOMPrpg1QX",
  organisation.unit = "DiszpKrYNg8",
  data.element.group = NULL,
  start.date = "2014",
  end.date = "2023"
)

# READING DATA FROM 2 DATASETS `pBOMPrpg1QX`
data <- readepi(
  credentials.file = credentials.file,
  project.id = "DHIS2_DEMO",
  dataset = "pBOMPrpg1QX,BfMAe6Itzgt", # same as dataset=c("pBOMPrpg1QX","BfMAe6Itzgt")
  organisation.unit = "DiszpKrYNg8",
  data.element.group = NULL,
  start.date = "2014",
  end.date = "2023"
)

# READING SPECIFIC DATA ELEMENTS FROM THE DATASET ID `pBOMPrpg1QX`
data.elts <- c("FTRrcoaog83", "eY5ehpbEsB7", "Ix2HsbDMLea")
data <- readepi(
  credentials.file = credentials.file,
  project.id = "DHIS2_DEMO",
  dataset = "pBOMPrpg1QX",
  organisation.unit = "DiszpKrYNg8",
  data.element.group = NULL,
  start.date = "2014",
  end.date = "2023",
  records = data.elts,
  id.col.name = "dataElement"
)

test.data <- data$data
```

## importing from Fingertips
[Fingertips](https://fingertips.phe.org.uk/) is a repository of public health data indicators in England. The data in Fingertips website is organised into themed profiles. The `readepi()` function takes the arguments listed below to import data from Fingertips through its API:     

* *indicator_id*: the indicator ID
* *indicator_name*: the indicator name
* *area_type_id*: the area type ID. This determines the geographic area for the imported data
* *parent_area_type_id*: the parent area type code of the specified area type ID
* *profile_id*: the profile ID
* *profile_name*: the profile name
* *domain_id*: the domain ID
* *domain_name*: the domain name
* *records*: the list of the desired records     
* *fields*: the list of the desired columns 
* *id.col.name*: the column name with the records of interest 
* *id.position*: the column position of the variable that unique identifies the subjects. default is 1. 

Note that the `readepi()` function makes call of wrapper around the major function in the [fingertipsR](https://docs.ropensci.org/fingertipsR/) package.    

```{r eval=FALSE}
# GET THE INFORMATION ABOUT THE INDICATOR PROFILES, DOMAIN, AREA TYPE, ...
metadata = get_fingertips_metadata()
head(metadata$indicator_profile_domain) #indicator_profile_domain contains the indicator, profile, and domain information.    
head(metadata$indicator_ids_names) #indicator_ids_names contains the list of indicators IDs together with their names.     
head(metadata$area_type) #area_type contains the list of all area types with their associated parent area types.

# IMPORTING DATA USING THE INDICATOR ID
data = readepi(indicator_id=90362, 
               area_type_id=202)

# IMPORTING DATA USING THE INDICATOR NAME
data = readepi(indicator_name="Healthy life expectancy at birth", 
               area_type_id=202)

# IMPORTING DATA USING THE DOMAIN NAME
data = readepi(indicator_name="A. Overarching indicators", 
                            area_type_id=202)

data = readepi(indicator_name="A. Overarching indicators", 
               area_type_id=202,
               indicator_name="Healthy life expectancy at birth")

# IMPORTING DATA USING THE PROFILE ID
data = readepi(profile_id=19, 
               area_type_id=202)

# IMPORTING DATA FROM SPECIFIC INDICATOR, DOMAIN, PROFILE, AREA TYPE 
data = readepi(indicator_id=90362, 
               indicator_name="Healthy life expectancy at birth",
               area_type_id=202, parent_area_type_id=6,
               profile_id=19, 
               profile_name="Public Health Outcomes Framework",
               domain_id=1000049, domain_name="A. Overarching indicators",
               fields=NULL, records=NULL,
               id.position=NULL, id.column.name=NULL
               )

# IMPORTING DATA AND SUBSETTING SPECIFIC RECORDS AND FIELDS
data = readepi(indicator_id=90362, 
               area_type_id=202, 
               fields=c("IndicatorID","AreaCode","Age","Value"),
               records=c("E92000001","E12000002","E12000009"),
               id.column.name="AreaCode"
               )
```



